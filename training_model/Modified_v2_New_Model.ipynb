{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Modified_v2 New Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktam069/Google_Colab_Audiovisual/blob/master/Copy_of_Copy_of_Modified_v2_New_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwOkfpDuXN_I",
        "colab_type": "code",
        "outputId": "b4c9dd9c-63f2-460a-8f6a-c090b2c05249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaTLXVI0wNjo",
        "colab_type": "code",
        "outputId": "f898724a-6aed-4fe1-dae2-e99f0734e783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm -r \"data/\"\n",
        "!unzip -q \"/content/gdrive/My Drive/Part IV Project/Colab Modified/data.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObNXwtb73BQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create AV model\n",
        "#############################################################\n",
        "RESTORE = True\n",
        "# If set true, continue training from last checkpoint\n",
        "# needed change 1:h5 file name, 2:epochs num, 3:initial_epoch\n",
        "\n",
        "# super parameters\n",
        "people_num = 2\n",
        "epochs = 10\n",
        "initial_epoch = 1\n",
        "batch_size = 2 # 4 to feed one 16G GPU\n",
        "gamma_loss = 0.1\n",
        "beta_loss = gamma_loss*2\n",
        "\n",
        "# physical devices option to accelerate training process\n",
        "workers = 1 # num of core\n",
        "use_multiprocessing = False\n",
        "NUM_GPU = 1\n",
        "\n",
        "# PATH\n",
        "path = 'saved_AV_models' # model path\n",
        "database_dir_path = 'data/'\n",
        "#############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8uihk09xmZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/Part IV Project/Colab TFServing/AVmodel-2p-002-0.87080.h5' \"{path}/AVmodel-2p-002-0.87080.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slDZqQWHsHfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/Part IV Project/Colab Modified/saved_models/saved_model_v2_01.h5' \"{path}/saved_model_v2_01.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnqdpHlTyy4p",
        "colab_type": "code",
        "outputId": "1c1e8072-d980-4365-d6e0-60f3422fa7e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  gdrive  log_AV  sample_data  saved_AV_models  saved_model_v2_01.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7F2KLz0y7E5",
        "colab_type": "code",
        "outputId": "a0446574-047e-4ee6-dcc6-346c73ce12a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"{path}\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AVmodel-2p-002-0.87080.h5  saved_model_v2_01.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-VSebCUfYZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from scipy.io import wavfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alYFRe80gYU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten, TimeDistributed, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp7FLs_3gZ7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# import sys\n",
        "import glob\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvHnxt-Wf7H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmnyVmexKxNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def audio_discriminate_loss2(gamma=0.1,beta = 2*0.1,num_speaker=2):\n",
        "    def loss_func(S_true,S_pred,gamma=gamma,beta=beta,num_speaker=num_speaker):\n",
        "        import keras.backend as K\n",
        "        sum_mtr = K.zeros_like(S_true[:,:,:,:,0])\n",
        "        for i in range(num_speaker):\n",
        "            sum_mtr += K.square(S_true[:,:,:,:,i]-S_pred[:,:,:,:,i])\n",
        "            for j in range(num_speaker):\n",
        "                if i != j:\n",
        "                    sum_mtr -= gamma*(K.square(S_true[:,:,:,:,i]-S_pred[:,:,:,:,j]))\n",
        "\n",
        "        for i in range(num_speaker):\n",
        "            for j in range(i+1,num_speaker):\n",
        "                #sum_mtr -= beta*K.square(S_pred[:,:,:,i]-S_pred[:,:,:,j])\n",
        "                #sum_mtr += beta*K.square(S_true[:,:,:,:,i]-S_true[:,:,:,:,j])\n",
        "                pass\n",
        "        #sum = K.sum(K.maximum(K.flatten(sum_mtr),0))\n",
        "\n",
        "        loss = K.mean(K.flatten(sum_mtr))\n",
        "\n",
        "        return loss\n",
        "    return loss_func\n",
        "\n",
        "audio_loss = audio_discriminate_loss2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR6ASQkWKm8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "class AVGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, filename, database_dir_path, X1dim=(298, 257, 2), X2dim=(75, 1, 1792, 2), ydim=(298, 257, 2, 2), batch_size=4, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.filename = filename\n",
        "        self.X1dim = X1dim\n",
        "        self.X2dim = X2dim\n",
        "        self.ydim = ydim\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.database_dir_path = database_dir_path\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.filename) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list\n",
        "        filename_temp = [self.filename[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        [X1, X2], y = self.__data_generation(filename_temp)\n",
        "\n",
        "        return [X1, X2], y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.filename))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, filename_temp):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        X1 = np.empty((self.batch_size, *self.X1dim))\n",
        "        X2 = np.empty((self.batch_size, *self.X2dim))\n",
        "        y = np.empty((self.batch_size, *self.ydim))\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(filename_temp):\n",
        "            info = ID.strip().split(' ')\n",
        "            X1[i, ] = np.load(self.database_dir_path+'audio/AV_model_database/mix/' + info[0])\n",
        "            for j in range(2):\n",
        "                y[i, :, :, :, j] = np.load(self.database_dir_path+'audio/AV_model_database/crm/' + info[j + 1])\n",
        "                X2[i, :, :, :, j] = np.load(self.database_dir_path+'video/face_emb/' + info[j + 3])\n",
        "\n",
        "        return [X1, X2], y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hQwz9gdLCLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AV_model(people_num=2):\n",
        "    def UpSampling2DBilinear(size):\n",
        "        return Lambda(lambda x: tf.image.resize_bilinear(x, size, align_corners=True))\n",
        "\n",
        "    def sliced(x, index):\n",
        "        return x[:, :, :, index]\n",
        "\n",
        "    # --------------------------- AS start ---------------------------\n",
        "    audio_input = Input(shape=(298, 257, 2))\n",
        "    print('as_0:', audio_input.shape)\n",
        "    as_conv1 = Convolution2D(96, kernel_size=(1, 7), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv1')(audio_input)\n",
        "    as_conv1 = BatchNormalization()(as_conv1)\n",
        "    as_conv1 = ReLU()(as_conv1)\n",
        "    print('as_1:', as_conv1.shape)\n",
        "\n",
        "    as_conv2 = Convolution2D(96, kernel_size=(7, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv2')(as_conv1)\n",
        "    as_conv2 = BatchNormalization()(as_conv2)\n",
        "    as_conv2 = ReLU()(as_conv2)\n",
        "    print('as_2:', as_conv2.shape)\n",
        "\n",
        "    as_conv3 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv3')(as_conv2)\n",
        "    as_conv3 = BatchNormalization()(as_conv3)\n",
        "    as_conv3 = ReLU()(as_conv3)\n",
        "    print('as_3:', as_conv3.shape)\n",
        "\n",
        "    as_conv4 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(2, 1), name='as_conv4')(as_conv3)\n",
        "    as_conv4 = BatchNormalization()(as_conv4)\n",
        "    as_conv4 = ReLU()(as_conv4)\n",
        "    print('as_4:', as_conv4.shape)\n",
        "\n",
        "    as_conv5 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(4, 1), name='as_conv5')(as_conv4)\n",
        "    as_conv5 = BatchNormalization()(as_conv5)\n",
        "    as_conv5 = ReLU()(as_conv5)\n",
        "    print('as_5:', as_conv5.shape)\n",
        "\n",
        "    as_conv6 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(8, 1), name='as_conv6')(as_conv5)\n",
        "    as_conv6 = BatchNormalization()(as_conv6)\n",
        "    as_conv6 = ReLU()(as_conv6)\n",
        "    print('as_6:', as_conv6.shape)\n",
        "\n",
        "    as_conv7 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(16, 1), name='as_conv7')(as_conv6)\n",
        "    as_conv7 = BatchNormalization()(as_conv7)\n",
        "    as_conv7 = ReLU()(as_conv7)\n",
        "    print('as_7:', as_conv7.shape)\n",
        "\n",
        "    as_conv8 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(32, 1), name='as_conv8')(as_conv7)\n",
        "    as_conv8 = BatchNormalization()(as_conv8)\n",
        "    as_conv8 = ReLU()(as_conv8)\n",
        "    print('as_8:', as_conv8.shape)\n",
        "\n",
        "    as_conv9 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv9')(as_conv8)\n",
        "    as_conv9 = BatchNormalization()(as_conv9)\n",
        "    as_conv9 = ReLU()(as_conv9)\n",
        "    print('as_9:', as_conv9.shape)\n",
        "\n",
        "    as_conv10 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(2, 2), name='as_conv10')(as_conv9)\n",
        "    as_conv10 = BatchNormalization()(as_conv10)\n",
        "    as_conv10 = ReLU()(as_conv10)\n",
        "    print('as_10:', as_conv10.shape)\n",
        "\n",
        "    as_conv11 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(4, 4), name='as_conv11')(as_conv10)\n",
        "    as_conv11 = BatchNormalization()(as_conv11)\n",
        "    as_conv11 = ReLU()(as_conv11)\n",
        "    print('as_11:', as_conv11.shape)\n",
        "\n",
        "    as_conv12 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(8, 8), name='as_conv12')(as_conv11)\n",
        "    as_conv12 = BatchNormalization()(as_conv12)\n",
        "    as_conv12 = ReLU()(as_conv12)\n",
        "    print('as_12:', as_conv12.shape)\n",
        "\n",
        "    as_conv13 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(16, 16), name='as_conv13')(as_conv12)\n",
        "    as_conv13 = BatchNormalization()(as_conv13)\n",
        "    as_conv13 = ReLU()(as_conv13)\n",
        "    print('as_13:', as_conv13.shape)\n",
        "\n",
        "    as_conv14 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(32, 32), name='as_conv14')(as_conv13)\n",
        "    as_conv14 = BatchNormalization()(as_conv14)\n",
        "    as_conv14 = ReLU()(as_conv14)\n",
        "    print('as_14:', as_conv14.shape)\n",
        "\n",
        "    as_conv15 = Convolution2D(8, kernel_size=(1, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv15')(as_conv14)\n",
        "    as_conv15 = BatchNormalization()(as_conv15)\n",
        "    as_conv15 = ReLU()(as_conv15)\n",
        "    print('as_15:', as_conv15.shape)\n",
        "\n",
        "    AS_out = Reshape((298, 8 * 257))(as_conv15)\n",
        "    print('AS_out:', AS_out.shape)\n",
        "    # --------------------------- AS end ---------------------------\n",
        "\n",
        "    # --------------------------- VS_model start ---------------------------\n",
        "    VS_model = Sequential()\n",
        "    VS_model.add(Convolution2D(256, kernel_size=(7, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='vs_conv1'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(256, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='vs_conv2'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(256, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(2, 1), name='vs_conv3'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(256, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(4, 1), name='vs_conv4'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(256, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(8, 1), name='vs_conv5'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(256, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(16, 1), name='vs_conv6'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Reshape((75, 256, 1)))\n",
        "    VS_model.add(UpSampling2DBilinear((298, 256)))\n",
        "    VS_model.add(Reshape((298, 256)))\n",
        "    # --------------------------- VS_model end ---------------------------\n",
        "\n",
        "    video_input = Input(shape=(75, 1, 1792, people_num))\n",
        "    AVfusion_list = [AS_out]\n",
        "    for i in range(people_num):\n",
        "        single_input = Lambda(sliced, arguments={'index': i})(video_input)\n",
        "        VS_out = VS_model(single_input)\n",
        "        AVfusion_list.append(VS_out)\n",
        "\n",
        "    AVfusion = concatenate(AVfusion_list, axis=2)\n",
        "    AVfusion = TimeDistributed(Flatten())(AVfusion)\n",
        "    print('AVfusion:', AVfusion.shape)\n",
        "\n",
        "    lstm = Bidirectional(LSTM(400, input_shape=(298, 8 * 257), return_sequences=True), merge_mode='sum')(AVfusion)\n",
        "    print('lstm:', lstm.shape)\n",
        "\n",
        "    fc1 = Dense(600, name=\"fc1\", activation='relu', kernel_initializer=he_normal(seed=27))(lstm)\n",
        "    print('fc1:', fc1.shape)\n",
        "    fc2 = Dense(600, name=\"fc2\", activation='relu', kernel_initializer=he_normal(seed=42))(fc1)\n",
        "    print('fc2:', fc2.shape)\n",
        "    fc3 = Dense(600, name=\"fc3\", activation='relu', kernel_initializer=he_normal(seed=65))(fc2)\n",
        "    print('fc3:', fc3.shape)\n",
        "\n",
        "    complex_mask = Dense(257 * 2 * people_num, name=\"complex_mask\", kernel_initializer=glorot_uniform(seed=87))(fc3)\n",
        "    print('complex_mask:', complex_mask.shape)\n",
        "\n",
        "    complex_mask_out = Reshape((298, 257, 2, people_num))(complex_mask)\n",
        "    print('complex_mask_out:', complex_mask_out.shape)\n",
        "\n",
        "    AV_model = Model(inputs=[audio_input, video_input], outputs=complex_mask_out)\n",
        "\n",
        "    # # compile AV_model\n",
        "    # AV_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return AV_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24qa38pMLGDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, argparse\n",
        "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
        "from keras import Model\n",
        "from keras.utils import multi_gpu_model\n",
        "\n",
        "class ModelMGPU(Model):\n",
        "    def __init__(self, ser_model, gpus):\n",
        "        pmodel = multi_gpu_model(ser_model, gpus)\n",
        "        self.__dict__.update(pmodel.__dict__)\n",
        "        self._smodel = ser_model\n",
        "\n",
        "    def __getattribute__(self, attrname):\n",
        "        '''Override load and save methods to be used from the serial-model. The\n",
        "        serial-model holds references to the weights in the multi-gpu model.\n",
        "        '''\n",
        "        # return Model.__getattribute__(self, attrname)\n",
        "        if 'load' in attrname or 'save' in attrname:\n",
        "            return getattr(self._smodel, attrname)\n",
        "\n",
        "        return super(ModelMGPU, self).__getattribute__(attrname)\n",
        "\n",
        "def latest_file(dir):\n",
        "    # get latest checkpoint\n",
        "    lists = os.listdir(dir)\n",
        "    lists.sort(key=lambda fn: os.path.getmtime(dir + fn))\n",
        "    file_latest = os.path.join(dir, lists[-1])\n",
        "    return file_latest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0418pgj3C2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# create folder to save models\n",
        "folder = os.path.exists(path)\n",
        "if not folder:\n",
        "\tos.makedirs(path)\n",
        "\tprint('create folder to save models')\n",
        "filepath = path + \"/AVmodel-\" + str(people_num) + \"p-{epoch:03d}-{val_loss:.5f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "\n",
        "#############################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWGFJKJsfkAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# automatically change lr\n",
        "def scheduler(epoch):\n",
        "\tini_lr = 0.00001\n",
        "\tlr = ini_lr\n",
        "\tif epoch >= 5:\n",
        "\t\tlr = ini_lr / 5\n",
        "\tif epoch >= 10:\n",
        "\t\tlr = ini_lr / 10\n",
        "\treturn lr\n",
        "\n",
        "rlr = LearningRateScheduler(scheduler, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yeA2MWYM16d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "# from tensorflow.keras.layers import Dense, Convolution3D, MaxPooling3D, ZeroPadding3D, Dropout, Flatten, BatchNormalization, ReLU\n",
        "from tensorflow.keras.models import Sequential, model_from_json\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Input, Dense, Convolution2D, Bidirectional, UpSampling2D, UpSampling3D, concatenate\n",
        "from tensorflow.keras.layers import Dropout, Flatten, BatchNormalization, ReLU, Reshape, Permute, Lambda, TimeDistributed\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "# from keras.layers.recurrent import LSTM\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.initializers import he_normal, glorot_uniform\n",
        "# from keras.layers import Deconvolution2D\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui65BarW3awC",
        "colab_type": "code",
        "outputId": "fd06ab7c-8852-46c8-ea7d-cde85b3666c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# read train and val file name\n",
        "# format: mix.npy single.npy single.npy\n",
        "trainfile = []\n",
        "valfile = []\n",
        "with open((database_dir_path+'AV_log/AVdataset_train.txt'), 'r') as t:\n",
        "\ttrainfile = t.readlines()\n",
        "with open((database_dir_path+'AV_log/AVdataset_val.txt'), 'r') as v:\n",
        "\tvalfile = v.readlines()\n",
        "# ///////////////////////////////////////////////////////// #\n",
        "\n",
        "loss = audio_loss(gamma=gamma_loss,beta=beta_loss, num_speaker=people_num)\n",
        "\n",
        "# the training steps\n",
        "if RESTORE:\n",
        "\tlatest_f = latest_file(path+'/')\n",
        "\tprint(\"Restoring model from:\", latest_f)\n",
        "\t#AV_model = load_model(latest_f,custom_objects={\"tf\": tf})\n",
        "\tAV_model = load_model(latest_f,custom_objects={\"tf\": tf, 'loss_func': loss})\n",
        "\t#info = latest_file.strip().split('-')\n",
        "\t#initial_epoch = int(info[-2])\n",
        "else:\n",
        "\tAV_model = AV_model(people_num)\n",
        "\n",
        "train_generator = AVGenerator(trainfile,database_dir_path= database_dir_path, batch_size=batch_size, shuffle=True)\n",
        "val_generator = AVGenerator(valfile,database_dir_path=database_dir_path, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restoring model from: saved_AV_models/saved_model_v2_01.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMXJcVOo3aul",
        "colab_type": "code",
        "outputId": "d9564207-722f-43a6-9a74-64c0bf57ccd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "adam = optimizers.Adam()\n",
        "#loss = audio_loss(gamma=gamma_loss,beta=beta_loss, num_speaker=people_num)\n",
        "AV_model.compile(optimizer=adam, loss=loss, metrics=['accuracy'])\n",
        "AV_model.summary()\n",
        "AV_model.fit_generator(generator=train_generator,\n",
        "             validation_data=val_generator,\n",
        "             epochs=epochs,\n",
        "             workers = workers,\n",
        "             use_multiprocessing= use_multiprocessing,\n",
        "             callbacks=[TensorBoard(log_dir='log_AV'), checkpoint, rlr],\n",
        "             initial_epoch=initial_epoch\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 298, 257, 2) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "as_conv1 (Conv2D)               (None, 298, 257, 96) 1440        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 298, 257, 96) 384         as_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 298, 257, 96) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "as_conv2 (Conv2D)               (None, 298, 257, 96) 64608       re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 298, 257, 96) 384         as_conv2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv3 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 298, 257, 96) 384         as_conv3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv4 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 298, 257, 96) 384         as_conv4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv5 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 298, 257, 96) 384         as_conv5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv6 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 298, 257, 96) 384         as_conv6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv7 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 298, 257, 96) 384         as_conv7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv8 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 298, 257, 96) 384         as_conv8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv9 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 298, 257, 96) 384         as_conv9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv10 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 298, 257, 96) 384         as_conv10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv11 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 298, 257, 96) 384         as_conv11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv12 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 298, 257, 96) 384         as_conv12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv13 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 298, 257, 96) 384         as_conv13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv14 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 298, 257, 96) 384         as_conv14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv15 (Conv2D)              (None, 298, 257, 8)  776         re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 298, 257, 8)  32          as_conv15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 75, 1, 1792, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 298, 257, 8)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 75, 1, 2)     0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 75, 1, 2)     0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 298, 2056)    0           re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 298, 256)     1649664     lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 298, 2568)    0           reshape[0][0]                    \n",
            "                                                                 sequential[0][0]                 \n",
            "                                                                 sequential[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 298, 2568)    0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 298, 400)     9500800     time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 298, 600)     240600      bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "fc2 (Dense)                     (None, 298, 600)     360600      fc1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "fc3 (Dense)                     (None, 298, 600)     360600      fc2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "complex_mask (Dense)            (None, 298, 1028)    617828      fc3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 298, 257, 2,  0           complex_mask[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 15,568,276\n",
            "Trainable params: 15,562,500\n",
            "Non-trainable params: 5,776\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 2/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.7697 - acc: 0.5016 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 5:05 - loss: 0.6597 - acc: 0.5032\n",
            "Epoch 00002: val_loss improved from inf to 0.65972, saving model to saved_AV_models/AVmodel-2p-002-0.65972.h5\n",
            "198/198 [==============================] - 1531s 8s/step - loss: 0.7687 - acc: 0.5018 - val_loss: 0.6597 - val_acc: 0.5032\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 3/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.6245 - acc: 0.5102 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 5:20 - loss: 0.6052 - acc: 0.5111\n",
            "Epoch 00003: val_loss improved from 0.65972 to 0.60518, saving model to saved_AV_models/AVmodel-2p-003-0.60518.h5\n",
            "198/198 [==============================] - 1456s 7s/step - loss: 0.6247 - acc: 0.5100 - val_loss: 0.6052 - val_acc: 0.5111\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 4/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.6076 - acc: 0.5162 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 6:04 - loss: 0.6043 - acc: 0.5121\n",
            "Epoch 00004: val_loss improved from 0.60518 to 0.60429, saving model to saved_AV_models/AVmodel-2p-004-0.60429.h5\n",
            "198/198 [==============================] - 1500s 8s/step - loss: 0.6073 - acc: 0.5161 - val_loss: 0.6043 - val_acc: 0.5121\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 5/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.6054 - acc: 0.5210 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 4:51 - loss: 0.6040 - acc: 0.5135\n",
            "Epoch 00005: val_loss improved from 0.60429 to 0.60402, saving model to saved_AV_models/AVmodel-2p-005-0.60402.h5\n",
            "198/198 [==============================] - 1447s 7s/step - loss: 0.6053 - acc: 0.5210 - val_loss: 0.6040 - val_acc: 0.5135\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 2.0000000000000003e-06.\n",
            "Epoch 6/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.6029 - acc: 0.5265 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 5:47 - loss: 0.6020 - acc: 0.5183\n",
            "Epoch 00006: val_loss improved from 0.60402 to 0.60200, saving model to saved_AV_models/AVmodel-2p-006-0.60200.h5\n",
            "198/198 [==============================] - 1495s 8s/step - loss: 0.6036 - acc: 0.5264 - val_loss: 0.6020 - val_acc: 0.5183\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 2.0000000000000003e-06.\n",
            "Epoch 7/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.6024 - acc: 0.5287 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 4:48 - loss: 0.6014 - acc: 0.5194\n",
            "Epoch 00007: val_loss improved from 0.60200 to 0.60143, saving model to saved_AV_models/AVmodel-2p-007-0.60143.h5\n",
            "198/198 [==============================] - 1473s 7s/step - loss: 0.6025 - acc: 0.5286 - val_loss: 0.6014 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 2.0000000000000003e-06.\n",
            "Epoch 8/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.6015 - acc: 0.5313 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 4:49 - loss: 0.6010 - acc: 0.5212\n",
            "Epoch 00008: val_loss improved from 0.60143 to 0.60104, saving model to saved_AV_models/AVmodel-2p-008-0.60104.h5\n",
            "198/198 [==============================] - 1447s 7s/step - loss: 0.6017 - acc: 0.5313 - val_loss: 0.6010 - val_acc: 0.5212\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 2.0000000000000003e-06.\n",
            "Epoch 9/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.6000 - acc: 0.5338 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 4:47 - loss: 0.6007 - acc: 0.5235\n",
            "Epoch 00009: val_loss improved from 0.60104 to 0.60065, saving model to saved_AV_models/AVmodel-2p-009-0.60065.h5\n",
            "198/198 [==============================] - 1440s 7s/step - loss: 0.6008 - acc: 0.5338 - val_loss: 0.6007 - val_acc: 0.5235\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 2.0000000000000003e-06.\n",
            "Epoch 10/10\n",
            "197/198 [============================>.] - ETA: 7s - loss: 0.5993 - acc: 0.5380 Epoch 1/10\n",
            " 22/198 [==>...........................] - ETA: 4:48 - loss: 0.5957 - acc: 0.5279\n",
            "Epoch 00010: val_loss improved from 0.60065 to 0.59569, saving model to saved_AV_models/AVmodel-2p-010-0.59569.h5\n",
            "198/198 [==============================] - 1430s 7s/step - loss: 0.5992 - acc: 0.5380 - val_loss: 0.5957 - val_acc: 0.5279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1441521fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffWqNibTfpRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tBeKTaffy4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWhymOQ77BO5",
        "colab_type": "code",
        "outputId": "d8351a7d-133e-4e65-fc50-e35bc70c61a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check connection to GPU\n",
        "tf.test.gpu_device_name() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LAUFKr7JWz",
        "colab_type": "code",
        "outputId": "4c24556c-ff58-4a8c-aa33-8330e9f23751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if 'COLAB_TPU_ADDR' not in os.environ: \n",
        "  print('Not connected to TPU') \n",
        "else: \n",
        "  print(\"Connected to TPU\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not connected to TPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC7aat3I8cmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7PTLdVM9ghw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_path = \"saved_model_v2_02.h5\"\n",
        "AV_model.save(model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S46pGkVu8wto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"saved_model_v2_02.h5\" '/content/gdrive/My Drive/Part IV Project/Colab Modified/saved_models/saved_model_v2_02.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcdtqSlKu2VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"saved_model_v2_02.h5\" '/content/gdrive/My Drive/Part IV Project/Colab Modified/saved_models/saved_model_v2_02.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIWspqYY0f5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewyY4shv0ZN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_path = \"saved_model_v2_03.h5\"\n",
        "AV_model.save(model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr8EhyCw0anR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"{model_save_path}\" '/content/gdrive/My Drive/Part IV Project/Colab Modified/saved_models/{model_save_path}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxPWMQU598ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R85Ber8d9Q8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc5WJW5OYNiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ9LvQTHf3BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}