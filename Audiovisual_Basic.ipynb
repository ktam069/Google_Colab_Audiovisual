{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audiovisual_Basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktam069/Google_Colab_Audiovisual/blob/master/Audiovisual_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_cynixGXYa-",
        "colab_type": "text"
      },
      "source": [
        "Connect to Google Drive to access npy dataset of audio input for training/testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwOkfpDuXN_I",
        "colab_type": "code",
        "outputId": "ec160ded-f277-4ef3-bf2f-d730031eee55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-VSebCUfYZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main program - Part IV Project 80 Basic Version\n",
        "\n",
        "# import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from scipy.io import wavfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alYFRe80gYU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten, TimeDistributed, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp7FLs_3gZ7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# import sys\n",
        "import glob\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvHnxt-Wf7H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ===== Settings =====\n",
        "\n",
        "# Display options\n",
        "PRINT_DATA = False\n",
        "DISPLAY_GRAPHS = False\n",
        "\n",
        "# Data transformation/processing\n",
        "NORMALISE_DATA = False\n",
        "POWER_ENCODE = True\n",
        "\n",
        "# Use float32 format for dataset ndarrays\n",
        "USE_FLOAT32 = True\n",
        "\n",
        "# Range of data to use for training (excludes END_ID)\n",
        "START_ID = 0\n",
        "END_ID = 21\n",
        "\n",
        "# Sampling rate\n",
        "SAMPLING_RATE = 16000\n",
        "\n",
        "# Filepaths to the locations for input audio-visual files\n",
        "# path_to_data = \"./data/\"\n",
        "path_to_data_audio = \"./data/audio/audio_train/\"\n",
        "path_to_data_video = \"./data/video/face_input/\"\n",
        "# audio_data_name = \"trim_audio_train%d.wav\"\n",
        "\n",
        "# Filepaths to the locations for saved data and models\n",
        "path_to_models = \"./saved_models/\"\n",
        "path_to_saved_datasets = \"./dataset_npy/\"\n",
        "path_to_outputs = \"./output_wavs/\"\n",
        "\n",
        "# ===================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWGFJKJsfkAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_data():\n",
        "\taudio_dataset = []\n",
        "\tprint(\"Loading data files %d to %d...\"%(START_ID,END_ID-1))\n",
        "\t\t\n",
        "\tfor data_num in range(START_ID, END_ID):\n",
        "\t\tprint(\"\\tLoading audio data file %d...\"%data_num, end='\\r', flush=True)\n",
        "\t\t\n",
        "\t\t# Load wav file into an array\n",
        "\t\tdata = load_wav(data_num)\n",
        "\t\tif data is None:\n",
        "\t\t\tcontinue\n",
        "\t\t\n",
        "\t\t# Convert the array into a spectrogram - for visualisation only\n",
        "\t\tif DISPLAY_GRAPHS:\n",
        "\t\t\tdata_tmp = wav_to_spectrogram(data)\n",
        "\t\t\tvisualise_data(data_tmp)\n",
        "\t\t\n",
        "\t\t# Add data point to clean audio data set\n",
        "\t\taudio_dataset.append(data)\n",
        "\t\n",
        "\tprint()\n",
        "\treturn audio_dataset\n",
        "\n",
        "def generate_dataset(clean_audio_dataset):\n",
        "\t# Generate a data set of mixed audio inputs (x) and corresponding clean audio outputs (y)\n",
        "\tdataset = []\n",
        "\t\n",
        "\tfor i in range(len(clean_audio_dataset)):\n",
        "\t\tfor j in range(i+1, len(clean_audio_dataset)):\n",
        "\t\t\t# Mix audio for 2 speakers (no noise)\n",
        "\t\t\tmixed_audio = clean_audio_dataset[i] + clean_audio_dataset[j]\n",
        "\t\t\t\n",
        "\t\t\t# Add data point to data set\n",
        "\t\t\tdataset.append([mixed_audio, clean_audio_dataset[i], clean_audio_dataset[j]])\n",
        "\t\n",
        "\treturn np.array(dataset)\n",
        "\n",
        "def dataset_to_spectrograms(dataset):\n",
        "\tdataset_spects = np.zeros((dataset.shape[0], 298, 257, 2, dataset.shape[1]))\n",
        "\t\n",
        "\t# for i in range(len(dataset)):\n",
        "\t\t# print(\"\\tConverting audio data %d/%d to spectrogram...\"%(i+1,len(dataset)), end='\\r', flush=True)\n",
        "\t\t\n",
        "\t\t# Convert the data array into a spectrogram\n",
        "\t\t# for j in range(dataset.shape[1]):\n",
        "\t\t\t# dataset_spects[i,:,:,:,j] = wav_to_spectrogram(dataset[i,j,:])\n",
        "\t\t\n",
        "\t\t# print(dataset_spects.shape, dataset.shape)\n",
        "\t\n",
        "\tprint(\"Converting audio data to spectrograms...\")\n",
        "\tdataset_spects = wav_to_spectrogram(dataset[:,:,:])\n",
        "\t# print(dataset_spects.shape, dataset.shape)\n",
        "\t\n",
        "\t# print()\n",
        "\treturn dataset_spects\n",
        "\n",
        "def dataset_labels_to_cRMs(dataset_spects):\n",
        "\tdataset_cRMs = np.zeros(dataset_spects.shape)\n",
        "\t\n",
        "\tprint(\"Converting outputs to cRMs...\")\n",
        "\t\t\n",
        "\t# print(dataset_spects.shape)\n",
        "\t\n",
        "\t# TODO: complete\n",
        "\tdataset_cRMs[:,:,:,:,0] = dataset_spects[:,:,:,:,0]\n",
        "\tdataset_cRMs[:,:,:,:,1] = cRM_encode(dataset_spects[:,:,:,:,0], dataset_spects[:,:,:,:,1])\n",
        "\tdataset_cRMs[:,:,:,:,2] = cRM_encode(dataset_spects[:,:,:,:,0], dataset_spects[:,:,:,:,2])\n",
        "\t\n",
        "\treturn dataset_cRMs\n",
        "\n",
        "def normalise_dataset(data):\n",
        "\tif type(data) is not np.ndarray:\n",
        "\t\tdata = np.array(data)\n",
        "\n",
        "\tif PRINT_DATA:\n",
        "\t\tprint(\"\\nData before normalisation:\")\t\n",
        "\t\tprint(data)\n",
        "\t\tprint(np.max(data))\n",
        "\t\n",
        "\tmax = np.max(data)\n",
        "\tif max > 0:\n",
        "\t\tdata = data / max\n",
        "\t\n",
        "\treturn data\n",
        "\n",
        "def load_wav(data_num):\n",
        "\ttry:\n",
        "\t\tif PRINT_DATA:\n",
        "\t\t\tprint(\"\\n\\n=== Loading audio file \"+str(data_num)+\" ===\")\n",
        "\t\t\n",
        "\t\t# Filepath of audio file to be loaded\n",
        "\t\tpath = path_to_data_audio + \"trim_audio_train%d.wav\"%data_num\n",
        "\t\t\n",
        "\t\t# Load wav file into an array (an ndarray)\n",
        "\t\tdata, _ = librosa.load(path, sr=SAMPLING_RATE)\n",
        "\t\t\n",
        "\t\tif PRINT_DATA:\n",
        "\t\t\tprint(\"\\nData after loading:\")\n",
        "\t\t\tprint(data.shape)\n",
        "\t\t\tprint(data)\n",
        "\texcept:\n",
        "\t\treturn None\n",
        "\t\n",
        "\treturn data\n",
        "\n",
        "def wav_to_spectrogram(data):\n",
        "\tassert len(data.shape) == 3, \"Unexpected shape for data input, should be (n_samples, n_speakers+1, t_samples)\"\n",
        "\t\n",
        "\t# == STFT ==\n",
        "\n",
        "\t# Data padding??...may not be needed (TODO)\n",
        "\tlength = data.shape[2]\n",
        "\t# new_power_base_2 = np.ceil(np.log(length)/np.log(2))\n",
        "\t# new_len = pow(2, int(new_power_base_2))\n",
        "\tnew_len = 48192 - 512\n",
        "\tshape = data.shape\n",
        "\tnew_shape = shape[:len(shape)-1] + (new_len,)\n",
        "\t\n",
        "\tif new_len > length:\n",
        "\t\tnew_data = np.zeros(new_shape)\n",
        "\t\tnew_data[:,:,:new_len] = data\n",
        "\telse:\n",
        "\t\tnew_data = np.zeros(new_shape)\n",
        "\t\tnew_data[:,:,:] = data[:,:,:new_len]\n",
        "\tdata = new_data.astype('float32')\n",
        "\t\n",
        "\t# Calculations taken from https://github.com/tensorflow/tensorflow/issues/24620\n",
        "\tsample_rate = 16000 #16kHz\n",
        "\twindow_size_ms = 25\n",
        "\twindow_stride_ms = 10\n",
        "\twindow_size_samples = int(sample_rate * window_size_ms / 1000)\n",
        "\twindow_stride_samples = int(sample_rate * window_stride_ms / 1000)\n",
        "\t\n",
        "\twindow_size_samples = 512\n",
        "\t\n",
        "\tif PRINT_DATA:\n",
        "\t\tprint(\"segment_size_samples\", len(data))\n",
        "\t\tprint(\"window_size_samples\", window_size_samples)\n",
        "\t\tprint(\"window_stride_samples\", window_stride_samples)\n",
        "\t\n",
        "\tdata = tf.signal.stft(data, \n",
        "\t\t\t\t\t\t   frame_length=window_size_samples,\n",
        "\t\t\t\t\t\t   frame_step=window_stride_samples,\n",
        "\t\t\t\t\t\t   fft_length=window_size_samples,\n",
        "\t\t\t\t\t\t   pad_end=True)\n",
        "\t\t\t\t\t\t   # pad_end=False)\n",
        "\t\n",
        "\t# data = tf.signal.stft(data, frame_length=512, frame_step=160, fft_length=512,\n",
        "\t\t\t\t# window_fn=tf.signal.hann_window, pad_end=False)\n",
        "\t\t\n",
        "\tdata = tf.Session().run(data)\n",
        "\t\n",
        "\t# print(data.shape)\n",
        "\tdata = np.moveaxis(data, 1, -1)\n",
        "\t# print(data.shape)\n",
        "\t\n",
        "\tif PRINT_DATA:\n",
        "\t\tprint(\"\\nData after STFT:\")\n",
        "\t\tprint(data.shape)\n",
        "\t\t# print(data)\n",
        "\t\n",
        "\tif DISPLAY_GRAPHS:\n",
        "\t\t# Plot spectrogram data\n",
        "\t\tplt.pcolormesh(np.abs(data.T))\n",
        "\t\tplt.title('STFT Magnitude')\n",
        "\t\tplt.ylabel('Frequency [Hz]')\n",
        "\t\tplt.xlabel('Time [sec]')\n",
        "\t\t# plt.show()\n",
        "\t\n",
        "\t# == Complex to Re/Im ==\n",
        "\t\n",
        "\tdata = convert_to_scalars_ndarray(data)\n",
        "\t\n",
        "\t# == Power Law Compression ==\n",
        "\t\n",
        "\t# TODO: test this\n",
        "\t\n",
        "\tif POWER_ENCODE: data = power_law_encode(data)\n",
        "\t# data = power_law_decode(data)\n",
        "\t\n",
        "\tif PRINT_DATA:\n",
        "\t\tprint(\"\\nData after conversion:\")\n",
        "\t\tprint(data.shape)\n",
        "\t\t# print(data)\n",
        "\t\n",
        "\treturn data\n",
        "\n",
        "def convert_to_scalars_ndarray(data):\n",
        "\t# Convert complex arrays into scalar components for Re and Im parts\n",
        "\t# Allows extra dimension for processing multiple samples (compared to convert_to_scalars)\n",
        "\t\n",
        "\tnew_s = data.shape + (2,)\n",
        "\tnew_data = np.zeros(new_s)\n",
        "\t\n",
        "\tnew_data[:,:,:,:,0] = data.real\n",
        "\tnew_data[:,:,:,:,1] = data.imag\n",
        "\t\n",
        "\tnew_data = np.moveaxis(new_data, -2, -1)\n",
        "\t\n",
        "\treturn new_data\n",
        "\n",
        "def convert_to_complex_ndarray(data):\n",
        "\t# Convert scalar components for Re and Im parts into complex arrays\n",
        "\t# Allows extra dimension for processing multiple samples (compared to convert_to_complex)\n",
        "\t\n",
        "\t# TODO: might need fixing (last two axes were in the wrong order - might not be fixed)\n",
        "\tdata = np.moveaxis(data, -2, -1)\n",
        "\t\n",
        "\tnew_s = data.shape[:-1]\n",
        "\tnew_data = np.zeros(new_s, dtype=complex)\n",
        "\t\n",
        "\tnew_data[:,:] = data[:,:,0] + data[:,:,1]*1j\n",
        "\t\n",
        "\treturn new_data\n",
        "\n",
        "def convert_to_scalars(data):\n",
        "\t# Convert complex arrays into scalar components for Re and Im parts\n",
        "\t# i.e. from [[ a+ib,... ]...] to [[ [a,b],... ]...]\n",
        "\t\n",
        "\ts = data.shape\n",
        "\tnew_s = (s[0],s[1],2)\n",
        "\tnew_data = np.zeros(new_s)\n",
        "\t\n",
        "\tnew_data[:,:,0] = data.real\n",
        "\tnew_data[:,:,1] = data.imag\n",
        "\t\n",
        "\treturn new_data\n",
        "\n",
        "def convert_to_complex(data):\n",
        "\t# Convert scalar components for Re and Im parts into complex arrays\n",
        "\t# i.e. from [[ [a,b],... ]...] to [[ a+ib,... ]...]\n",
        "\t\n",
        "\ts = data.shape\n",
        "\tnew_s = (s[0],s[1])\n",
        "\tnew_data = np.zeros(new_s, dtype=complex)\n",
        "\t\n",
        "\tnew_data[:,:] = data[:,:,0] + data[:,:,1]*1j\n",
        "\t\n",
        "\treturn new_data\n",
        "\n",
        "def power_law_encode(data, power=0.3):\n",
        "\t# Retain the original +ve/-ve signs\n",
        "\tsigns = np.sign(data)\n",
        "\tcompressed_data = np.power(np.abs(data), power)\n",
        "\treturn compressed_data * signs\n",
        "\n",
        "def power_law_decode(data, power=0.3):\n",
        "\treturn power_law_encode(data, power=1.0/power)\n",
        "\n",
        "def cRM_encode(S_spect, Y_spect):\n",
        "\t# Create a complex (ideal) ratio mask of the spectrogram input\n",
        "\t# S and Y are the STFT of the clean and noisy signals respectively\n",
        "\t\n",
        "\toutput_mask = np.zeros(S_spect.shape)\n",
        "\t\n",
        "\t# Note: spectrogram shape is (298, 257, 2) - storing real and complex components\n",
        "\tS_spect_re = S_spect[:,:,:,0]\n",
        "\tS_spect_im = S_spect[:,:,:,1]\n",
        "\tY_spect_re = Y_spect[:,:,:,0]\n",
        "\tY_spect_im = Y_spect[:,:,:,1]\n",
        "\t\n",
        "\t# Use a small term (ep) to avoid division by zero\n",
        "\tep = 1e-8\n",
        "\tdenominator    = (Y_spect_re * Y_spect_re + Y_spect_im * Y_spect_im) + ep\n",
        "\t\n",
        "\toutput_mask_re = (Y_spect_re * S_spect_re + Y_spect_im * S_spect_im) / denominator\n",
        "\toutput_mask_im = (Y_spect_re * S_spect_im - Y_spect_im * S_spect_re) / denominator\n",
        "\t\n",
        "\toutput_mask[:,:,:,0] = output_mask_re\n",
        "\toutput_mask[:,:,:,1] = output_mask_im\n",
        "\t\n",
        "\treturn output_mask\n",
        "\n",
        "def cRM_decode(cRM_output, Y_spect):\n",
        "\t# (Apply complex mask to input spectrogram)\n",
        "\t# Multiply the complex ratio mask by the original noisy spectrogram to get the clean spectrogram\n",
        "\t# Needs to decompress the ratio mask beforehand\n",
        "\t\n",
        "\toutput_spect = np.zeros(cRM_output.shape)\n",
        "\t\n",
        "\tcRM_re = cRM_output[:,:,:,0]\n",
        "\tcRM_im = cRM_output[:,:,:,1]\n",
        "\tY_spect_re = Y_spect[:,:,:,0]\n",
        "\tY_spect_im = Y_spect[:,:,:,1]\n",
        "\t\n",
        "\t# Multiplication of complex numbers: (a1+i*b1)(a2+i*b2) = (a1*a2-b1*b2) + i(a1*b1+a2*b2)\n",
        "\toutput_spect_re = Y_spect_re * cRM_re - Y_spect_im * cRM_im\n",
        "\toutput_spect_im = Y_spect_re * cRM_im + Y_spect_im * cRM_re\n",
        "\t\n",
        "\toutput_spect[:,:,:,0] = output_spect_re\n",
        "\toutput_spect[:,:,:,1] = output_spect_im\n",
        "\t\t\n",
        "\treturn output_spect\n",
        "\t\n",
        "def visualise_data(data):\n",
        "\t# Visualise real and imaginary data components\n",
        "\t\n",
        "\tplt.close()\n",
        "\t\n",
        "\t# Plot display settings\n",
        "\tplt.figure(figsize=(20, 10))\n",
        "\tplt.subplots_adjust(left=0.05, bottom=0.05, right=0.95, top=0.95, wspace=0.2, hspace=0.2)\n",
        "\n",
        "\tx = lambda a: 'Real' if a==0 else 'Imaginary'\n",
        "\tfor i in range(2):\n",
        "\t\tplt.subplot(1, 3, i+1)\n",
        "\t\n",
        "\t\tplt.pcolormesh(np.abs(data[:,:,i].T))\n",
        "\t\tplt.title(x(i))\n",
        "\t\tplt.ylabel('Frequency [Hz]')\n",
        "\t\tplt.xlabel('Time [sec]')\n",
        "\t\t\n",
        "\tplt.subplot(1, 3, 3)\n",
        "\t\n",
        "\tplt.pcolormesh(np.abs(convert_to_complex(data).T))\n",
        "\tplt.title('Complex')\n",
        "\tplt.ylabel('Frequency [Hz]')\n",
        "\tplt.xlabel('Time [sec]')\n",
        "\tplt.show()\n",
        "\n",
        "def visualise_model_output(output_list, input_mixed):\t\n",
        "\tplt.close()\n",
        "\t\n",
        "\t# Plot display settings\n",
        "\tplt.figure(figsize=(20, 10))\n",
        "\tplt.subplots_adjust(left=0.05, bottom=0.05, right=0.95, top=0.95, wspace=0.2, hspace=0.2)\n",
        "\t\n",
        "\tplt.subplot(1, 3, 1)\n",
        "\t\n",
        "\tplt.pcolormesh(np.abs(convert_to_complex(input_mixed).T))\n",
        "\tplt.title('Mixed Input')\n",
        "\tplt.ylabel('Frequency [Hz]')\n",
        "\tplt.xlabel('Time [sec]')\n",
        "\n",
        "\tx = lambda a: 'Part 1 Out' if a==0 else 'Part 2 Out'\n",
        "\tfor i in range(2):\n",
        "\t\tplt.subplot(1, 3, i+2)\n",
        "\t\t\n",
        "\t\tspect = convert_to_complex(output_list[i])\n",
        "\t\tplt.pcolormesh(np.abs(spect.T))\n",
        "\t\tplt.title(x(i))\n",
        "\t\tplt.ylabel('Frequency [Hz]')\n",
        "\t\tplt.xlabel('Time [sec]')\n",
        "\t\n",
        "\tplt.show()\n",
        "\n",
        "def train_model(x_train, y_train, num_speakers=2):\n",
        "\tassert x_train[0].shape == (298, 257, 2), \"Data shape is incorrect - expected (298, 257, 2), got \"+str(x_train[0].shape)\n",
        "\t\n",
        "\t# Create a compiled model\n",
        "\tmodel = convolution_model()\n",
        "\t\n",
        "\t# Process training data\n",
        "\tpass\n",
        "\t# x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\t\n",
        "\tt = datetime.now().strftime(\"%d_%m_%H%M%S\")\n",
        "\t\n",
        "\t# Create checkpoints when training model (save models to file)\n",
        "\t# filepath = path_to_models + \"basic-ao-%s-{epoch:02d}-{loss:.2f}.h5\"%t\n",
        "\t# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\tfilepath = path_to_models + \"basic-ao-%s-{epoch:02d}-{val_loss:.2f}.h5\"%t\n",
        "\tcheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\t# checkpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=False)\n",
        "\tcallback_list = [checkpoint]\n",
        "\t\n",
        "\t# Train the model\n",
        "\t# model.fit(x_train, y_train, batch_size=6, epochs=30, callbacks=callback_list, verbose=1)\t\t# TODO: adjust the arguments used\n",
        "\t# model.fit(x_train, y_train, batch_size=6, epochs=20, callbacks=callback_list, verbose=1)\t\t# TODO: adjust the arguments used\n",
        "\tmodel.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=20, callbacks=callback_list, verbose=1, validation_split=0.1)\t\t# TODO: adjust the arguments used\n",
        "\n",
        "def convolution_model(num_speakers=2):\n",
        "\n",
        "\t# == Audio convolution layers ==\n",
        "\t\n",
        "\tmodel = Sequential()\n",
        "\t\n",
        "\t# # Implicit input layer\n",
        "\t# inputs = Input(shape=(298, 257, 2))\n",
        "\t# model.add(inputs)\n",
        "\t\n",
        "\t# Convolution layers\n",
        "\tconv1 = Conv2D(96, kernel_size=(1,7), padding='same', dilation_rate=(1,1), input_shape=(298, 257, 2))\n",
        "\tmodel.add(conv1)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv2 = Conv2D(96, kernel_size=(7,1), padding='same', dilation_rate=(1,1))\n",
        "\tmodel.add(conv2)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv3 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(1,1))\n",
        "\tmodel.add(conv3)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv4 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(2,1))\n",
        "\tmodel.add(conv4)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv5 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(4,1))\n",
        "\tmodel.add(conv5)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv6 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(8,1))\n",
        "\tmodel.add(conv6)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv7 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(16,1))\n",
        "\tmodel.add(conv7)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv8 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(32,1))\n",
        "\tmodel.add(conv8)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv9 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(1,1))\n",
        "\tmodel.add(conv9)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv10 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(2,2))\n",
        "\tmodel.add(conv10)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv11 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(4,4))\n",
        "\tmodel.add(conv11)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv12 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(8,8))\n",
        "\tmodel.add(conv12)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv13 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(16,16))\n",
        "\tmodel.add(conv13)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv14 = Conv2D(96, kernel_size=(5,5), padding='same', dilation_rate=(32,32))\n",
        "\tmodel.add(conv14)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\tconv15 = Conv2D(8, kernel_size=(1,1), padding='same', dilation_rate=(1,1))\n",
        "\tmodel.add(conv15)\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\t\n",
        "\t# == AV fused neural network ==\n",
        "\t\n",
        "\t# AV fusion step(s)\n",
        "\tmodel.add(TimeDistributed(Flatten()))\n",
        "\t\n",
        "\t# BLSTM\n",
        "\tnew_matrix_length = 400\n",
        "\tmodel.add(Bidirectional(LSTM(new_matrix_length//2, return_sequences=True, input_shape=(298, 257*8))))\n",
        "\t\n",
        "\t# Fully connected layers\n",
        "\tmodel.add(Dense(600, activation=\"relu\"))\n",
        "\tmodel.add(Dense(600, activation=\"relu\"))\n",
        "\tmodel.add(Dense(600, activation=\"relu\"))\n",
        "\t\n",
        "\t# Output layer (i.e. complex masks)\n",
        "\t# outputs = Dense(257*2*num_speakers, activation=\"relu\")\n",
        "\toutputs = Dense(257*2*num_speakers, activation=\"sigmoid\")\t\t\t\t# TODO: check if this is more correct (based on the paper)\n",
        "\tmodel.add(outputs)\n",
        "\toutputs_complex_masks = Reshape((298, 257, 2, num_speakers))\n",
        "\tmodel.add(outputs_complex_masks)\n",
        "\t\n",
        "\t# Print the output shapes of each model layer\n",
        "\tfor layer in model.layers:\n",
        "\t\tname = layer.get_config()[\"name\"]\n",
        "\t\tif \"batch_normal\" in name or \"activation\" in name:\n",
        "\t\t\tcontinue\n",
        "\t\tprint(layer.output_shape, \"\\t\", name)\n",
        "\t\n",
        "\t# Alternatively, print the default keras model summary\n",
        "\tprint(model.summary())\n",
        "\t\n",
        "\t# Compile the model before training\n",
        "\t# model.compile(optimizer='adam', loss='mse')\n",
        "\tmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\t\n",
        "\treturn model\n",
        "\n",
        "def test_model(x_test, y_test):\n",
        "\t# Test using the newest available model\n",
        "\tall_model_paths = glob.glob(path_to_models+'*')\n",
        "\tnewest_model_path = max(all_model_paths, key=os.path.getctime)\n",
        "\t\n",
        "\t# newest_model_path\n",
        "\t\n",
        "\t# Create a compiled model\n",
        "\tmodel = convolution_model()\n",
        "\t\n",
        "\t# Load weights from the last saved model\n",
        "\tmodel.load_weights(newest_model_path)\n",
        "\t\n",
        "\t# TODO / Temp: Save model for mobile append\n",
        "\tt = datetime.now().strftime(\"%d_%m_%H%M%S\")\n",
        "\tmodel_save_path = path_to_models + \"saved_model_basic_%s.h5\"%t\n",
        "\t# model.save(model_save_path)\n",
        "\t\n",
        "\t# TODO / Temp: Checking that the model loads\n",
        "\t# new_model = load_model(model_save_path)\n",
        "\tnew_model = load_model(newest_model_path)\n",
        "\tprint(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\tprint(\"Using model loaded from:\", newest_model_path)\n",
        "\tprint(\"\\nLoaded model summary:\")\n",
        "\tprint(new_model.summary())\n",
        "\t\n",
        "\tprint(\"\\nEvaluating on test data...\")\n",
        "\t\n",
        "\t# print(x_test.shape, y_test.shape)\n",
        "\t\n",
        "\tloss = model.evaluate(x_test, y_test)\n",
        "\tfor i in range(len(model.metrics_names)):\n",
        "\t\tprint(model.metrics_names[i]+\":\", loss[i])\n",
        "\t\n",
        "\toutput_spects = new_model.predict(x_test)\n",
        "\t# print(type(output_spects))\n",
        "\tprint(output_spects.shape)\n",
        "\t# print(output_spects)\n",
        "\t\n",
        "\t# ==================================================================================\n",
        "\t# Visualise the spectrograms for the first entry of the test set - testing purposes\n",
        "\t\n",
        "\tmixed_spect = x_test[0]\n",
        "\t\n",
        "\t# Predicted output cRM / spectrograms\n",
        "\tp1_spect = cRM_decode(output_spects[:,:,:,0], x_test)[0]\n",
        "\tp2_spect = cRM_decode(output_spects[:,:,:,1], x_test)[0]\n",
        "\t\n",
        "\t# Display mixed input and predicted outputs\n",
        "\tvisualise_model_output([p1_spect, p2_spect], mixed_spect)\n",
        "\t\n",
        "\t# Display actual clean spectrograms\n",
        "\tp1_spect_actual = cRM_decode(y_test[:,:,:,0], x_test)[0]\n",
        "\tp2_spect_actual = cRM_decode(y_test[:,:,:,1], x_test)[0]\n",
        "\t\n",
        "\t# Display mixed input and original clean audio wavs\n",
        "\tvisualise_model_output([p1_spect_actual, p2_spect_actual], mixed_spect)\n",
        "\t\n",
        "\t# Display cRMs\n",
        "\tprint(\"Displaying cRMs\")\n",
        "\tp1_cRM = output_spects[0][:,:,:,0]\n",
        "\tp2_cRM = output_spects[0][:,:,:,1]\n",
        "\tp1_cRM_actual = y_test[0][:,:,:,0]\n",
        "\tp2_cRM_actual = y_test[0][:,:,:,1]\n",
        "\tvisualise_model_output([p1_cRM, p2_cRM], mixed_spect)\n",
        "\tvisualise_model_output([p1_cRM_actual, p2_cRM_actual], mixed_spect)\n",
        "\t\n",
        "\t# ==================================================================================\n",
        "\t\n",
        "\t# Convert separated speech spectrograms to wav files\n",
        "\t# output_spects = spectrogram_to_wav(output_spects)\n",
        "\t\n",
        "\t# wavfile.write(path_to_outputs+\"output_file_%s_p1.wav\"%t, SAMPLING_RATE, p1_spect)\n",
        "\t# wavfile.write(path_to_outputs+\"output_file_%s_p2.wav\"%t, SAMPLING_RATE, p2_spect)\n",
        "\t\n",
        "\t# print(\"Output file saved\")\n",
        "\t\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffWqNibTfpRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def main():\n",
        "\t\n",
        "\t# Generate data set to use for training\n",
        "\tfilepath = path_to_saved_datasets+\"dataset_train_%d-%d.npy\"%(START_ID,END_ID-1)\n",
        "\tif not os.path.exists(filepath):\n",
        "\t\t# Load the data set of AV data, mix, and convert to spectrograms\n",
        "\t\taudio_wav = load_data()\n",
        "\t\tdataset_wav = generate_dataset(audio_wav)\n",
        "\t\tdataset_train = dataset_to_spectrograms(dataset_wav)\n",
        "\t\tdataset_train = dataset_labels_to_cRMs(dataset_train)\n",
        "\t\tif NORMALISE_DATA: dataset_train = normalise_dataset(dataset_train)\n",
        "\t\tprint(\"Finished converting dataset to spectrograms and cRMs\\n\")\n",
        "\t\t\n",
        "\t\tif USE_FLOAT32:\n",
        "\t\t\tdataset_train = dataset_train.astype('float32')\n",
        "\t\t\n",
        "\t\tnp.save(filepath, dataset_train)\n",
        "\telse:\n",
        "\t\t# Use existing generated data set\n",
        "\t\tprint(\"Loading data set from file:\", filepath)\n",
        "\t\tdataset_train = np.load(filepath)\n",
        "\t\n",
        "\t# Split dataset into inputs and ground truths\n",
        "\tx_train = dataset_train[:,:,:,:,0 ]\n",
        "\ty_train = dataset_train[:,:,:,:,1:]\n",
        "\t\n",
        "\t# # Build and train the neural network\n",
        "\ttrain_model(x_train, y_train)\n",
        "\t\n",
        "\t# Test model - temporarily just using the training data to test for errors\n",
        "\ttest_model(x_train[0:1], y_train[0:1])\n",
        "\t\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tBeKTaffy4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create any missing folders for saving data and outputs\n",
        "if not os.path.exists(path_to_models):\n",
        "  os.mkdir(path_to_models)\n",
        "if not os.path.exists(path_to_saved_datasets):\n",
        "  os.mkdir(path_to_saved_datasets)\n",
        "if not os.path.exists(path_to_outputs):\n",
        "  os.mkdir(path_to_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWhymOQ77BO5",
        "colab_type": "code",
        "outputId": "d559be6e-4921-4438-a83e-a5403afb0db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check connection to GPU\n",
        "tf.test.gpu_device_name() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LAUFKr7JWz",
        "colab_type": "code",
        "outputId": "1385a0ab-ad47-4797-e8c7-96e09ff481b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if 'COLAB_TPU_ADDR' not in os.environ: \n",
        "  print('Not connected to TPU') \n",
        "else: \n",
        "  print(\"Connected to TPU\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not connected to TPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC7aat3I8cmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive \n",
        "#drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7PTLdVM9ghw",
        "colab_type": "code",
        "outputId": "c52f003d-084d-4488-a86e-f77c367f1d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/gdrive/My Drive/Part IV Project/Colab Notebooks/dataset_npy/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_train_0-20.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S46pGkVu8wto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/gdrive/My Drive/Part IV Project/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxPWMQU598ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/Part IV Project/Colab Notebooks/dataset_npy/dataset_train_0-20.npy' \"dataset_npy/dataset_train_0-20.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R85Ber8d9Q8F",
        "colab_type": "code",
        "outputId": "e2387d60-c920-4fe1-c204-c56cb2629943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"dataset_npy/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_train_0-20.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc5WJW5OYNiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ9LvQTHf3BL",
        "colab_type": "code",
        "outputId": "1ada78bf-e0f8-4013-9baf-905127b89ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run AV speech separation program\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data set from file: ./dataset_npy/dataset_train_0-20.npy\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "(None, 298, 257, 96) \t conv2d\n",
            "(None, 298, 257, 96) \t conv2d_1\n",
            "(None, 298, 257, 96) \t conv2d_2\n",
            "(None, 298, 257, 96) \t conv2d_3\n",
            "(None, 298, 257, 96) \t conv2d_4\n",
            "(None, 298, 257, 96) \t conv2d_5\n",
            "(None, 298, 257, 96) \t conv2d_6\n",
            "(None, 298, 257, 96) \t conv2d_7\n",
            "(None, 298, 257, 96) \t conv2d_8\n",
            "(None, 298, 257, 96) \t conv2d_9\n",
            "(None, 298, 257, 96) \t conv2d_10\n",
            "(None, 298, 257, 96) \t conv2d_11\n",
            "(None, 298, 257, 96) \t conv2d_12\n",
            "(None, 298, 257, 96) \t conv2d_13\n",
            "(None, 298, 257, 8) \t conv2d_14\n",
            "(None, 298, 2056) \t time_distributed\n",
            "(None, 298, 400) \t bidirectional\n",
            "(None, 298, 600) \t dense\n",
            "(None, 298, 600) \t dense_1\n",
            "(None, 298, 600) \t dense_2\n",
            "(None, 298, 1028) \t dense_3\n",
            "(None, 298, 257, 2, 2) \t reshape\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 257, 96)      1440      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 298, 257, 96)      64608     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 298, 257, 96)      230496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 298, 257, 96)      384       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 298, 257, 96)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 298, 257, 8)       776       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 298, 257, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 298, 257, 8)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 298, 2056)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 298, 400)          3611200   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 298, 600)          240600    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 298, 600)          360600    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 298, 600)          360600    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 298, 1028)         617828    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 298, 257, 2, 2)    0         \n",
            "=================================================================\n",
            "Total params: 8,029,012\n",
            "Trainable params: 8,026,308\n",
            "Non-trainable params: 2,704\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 189 samples, validate on 21 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2575 - acc: 0.4995\n",
            "Epoch 00001: val_loss improved from inf to 2.97504, saving model to ./saved_models/basic-ao-21_09_081024-01-2.98.h5\n",
            "189/189 [==============================] - 321s 2s/sample - loss: 2.2642 - acc: 0.4992 - val_loss: 2.9750 - val_acc: 0.4949\n",
            "Epoch 2/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2501 - acc: 0.5011\n",
            "Epoch 00002: val_loss did not improve from 2.97504\n",
            "189/189 [==============================] - 297s 2s/sample - loss: 2.2549 - acc: 0.5013 - val_loss: 2.9765 - val_acc: 0.4902\n",
            "Epoch 3/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2563 - acc: 0.5007\n",
            "Epoch 00003: val_loss improved from 2.97504 to 2.97242, saving model to ./saved_models/basic-ao-21_09_081024-03-2.97.h5\n",
            "189/189 [==============================] - 297s 2s/sample - loss: 2.2550 - acc: 0.5008 - val_loss: 2.9724 - val_acc: 0.5037\n",
            "Epoch 4/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2478 - acc: 0.5013\n",
            "Epoch 00004: val_loss did not improve from 2.97242\n",
            "189/189 [==============================] - 297s 2s/sample - loss: 2.2544 - acc: 0.5013 - val_loss: 2.9733 - val_acc: 0.4989\n",
            "Epoch 5/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2137 - acc: 0.5027\n",
            "Epoch 00005: val_loss did not improve from 2.97242\n",
            "189/189 [==============================] - 297s 2s/sample - loss: 2.2547 - acc: 0.5028 - val_loss: 2.9725 - val_acc: 0.5047\n",
            "Epoch 6/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2695 - acc: 0.5021\n",
            "Epoch 00006: val_loss improved from 2.97242 to 2.97130, saving model to ./saved_models/basic-ao-21_09_081024-06-2.97.h5\n",
            "189/189 [==============================] - 297s 2s/sample - loss: 2.2543 - acc: 0.5022 - val_loss: 2.9713 - val_acc: 0.5081\n",
            "Epoch 7/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2665 - acc: 0.5010\n",
            "Epoch 00007: val_loss did not improve from 2.97130\n",
            "189/189 [==============================] - 297s 2s/sample - loss: 2.2542 - acc: 0.5011 - val_loss: 2.9747 - val_acc: 0.4948\n",
            "Epoch 8/20\n",
            "186/189 [============================>.] - ETA: 4s - loss: 2.2375 - acc: 0.5023\n",
            "Epoch 00008: val_loss did not improve from 2.97130\n",
            "189/189 [==============================] - 300s 2s/sample - loss: 2.2540 - acc: 0.5022 - val_loss: 2.9751 - val_acc: 0.4932\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}